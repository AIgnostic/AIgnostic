import requests
from bs4 import BeautifulSoup
import re
from .constants import property_to_metrics, property_to_regulations
from llm_insights.insights import init_llm, metric_insights
from common.models.common import LegislationInfo, LegislationInformation


def search_legislation(metric: str) -> list:
    """
    Searches for relevant legal sections based on a metric.
    Returns a list of matching articles.
    """
    result = []
    for property, metrics in property_to_metrics.items():
        if metric in metrics:
            result.extend(property_to_regulations[property])
            break

    return result


def extract_legislation_text(article_num: str, url: str, article_extension: callable) -> str:
    """
    Extracts text from the specified article of GDPR or AI Act.
    """
    print("extract_legislation_text: Entered into extract legislation text")
    url_extension = article_extension(article_num)
    legislation_url = url + url_extension
    print("extract_legislation_text: url: ", legislation_url)

    response = requests.get(legislation_url)
    if response.status_code != 200:
        return f"Failed to fetch Article {article_num}."
    soup = BeautifulSoup(response.text, "html.parser")
    article_content = soup.find("article")
    if not article_content:
        return f"Could not parse content for Article {article_num}."

    return article_content.get_text(separator="\n").strip()


def parse_legislation_text(article_content: str, article_num: str, article_type: str, info: LegislationInfo, url: str, article_extension: callable) -> dict:
    """
    Parses the raw article content into structured data.
    """
    data = {
        "article_type": article_type,
        "article_number": article_num,
        "article_title": "",
        "link": "",
        "description": "",
        "suitable_recitals": [],
    }
    text_lines = [
        re.sub(r"\s+", " ", line.strip())
        for line in article_content.split("\n")
        if line.strip()
    ]

    i = 0
    while i < len(text_lines):
        line = text_lines[i]

        # Extract Article Title
        type = ""
        if article_type.upper() == "GDPR":
            type = "GDPR"
        else:
            type = "AI Act"  # TODO: EXTEND TO A SWITCH CASE STATEMENT
        
        if line.startswith(f"Art. {article_num} {type}") and i + 1 < len(text_lines):
            data["article_title"] = text_lines[i + 1]
            i += 1

        # Extract Description
        elif (
            "Suitable Recitals" not in line
            and not line.startswith("Art.")
            and type not in line
        ):
            data["description"] += line + " "

        # Extract Suitable Recitals
        elif "Suitable Recitals" in line:
            i += 1
            while i < len(text_lines) and not text_lines[i].startswith("Art."):
                match = re.search(r"\b(\d+)\b", text_lines[i])
                if match:
                    recital_number = match.group(1)
                    recital_number_extension = ""
                    if type.lower() == "gdpr":
                        recital_number_extension = f"no-{recital_number}"
                    else:
                        # EU-AI Act
                        recital_number_extension = recital_number
                    recital_link = f"{info.url}/recitals/{recital_number_extension}/"
                    data["suitable_recitals"].append(recital_link)
                i += 1
            break

        i += 1


    link = url + article_extension(article_num)
    data["link"] = link
    data["description"] = data["description"].strip()
    return data



def get_legislation_extracts(metrics_data: dict, legislation: LegislationInformation) -> list[dict]:
    """
    Generates a comprehensive report based on the provided metrics data and API key.

    Args:
        metrics_data (dict): A dictionary mapping metrics to a similar form of a MetricValue model.
        api_key (str): The API key required to initialize the language model (LLM).
        legislation (dict): A dictionary mapping legislation ids to information for accessing extracts.

    Returns:
        list[dict]: Each includes:
            - "property" (str): The name of the property.
            - "computed_metrics" (list[dict]): Metrics mapping to their MetricValue Pydantic objects.
            - "legislation_extracts" (list): A list of parsed legislation extracts related to the property.
            - "llm_insights" (list): A list containing insights generated by the language model.
    """
    results = []
    computed_metrics = set(metrics_data.keys())
    print("Legislation:", legislation)
    for property in property_to_metrics.keys():
        property_result = {}
        # find the intersection of computed metrics and metrics for the property
        property_metrics = set(
            [p.replace(" ", "_") for p in property_to_metrics[property]]
        )
        common_metrics = computed_metrics.intersection(property_metrics)
        property_result["property"] = property

        computed_metrics_list = []
        for metric in common_metrics:
            metric_data = metrics_data.get(metric, {})
            error = metric_data.get("error", False)

            computed_metrics_list.append({
                "metric": metric.replace("_", " "),
                "value": 0 if error else round(metric_data.get("value", 0), 3),
                "ideal_value": None if error else round(metric_data.get("ideal_value", 0), 3),
                "range": None if error else metric_data.get("range"),
                "error": error or None,
            })

        property_result["computed_metrics"] = computed_metrics_list

        print("Reached this point before legislation insight.")
        print("Legislation", legislation)
        property_result["legislation_extracts"] = []
        dictionary = legislation
        for id, info in dictionary.items():
            name = info.name
            url = info.url
            article_extract = info.article_extract 
            print(f"Legislation checker: {name}, {url}, {article_extract}")
            for regulations in property_to_regulations[property]:
                print(f"Entered in regulations")
                article_content = extract_legislation_text(
                    regulations, 
                    url, 
                    article_extract)
                print(f"Finished extracting article content")
                parsed_data = parse_legislation_text(
                    article_content, 
                    regulations, 
                    id, 
                    info, 
                    url, 
                    article_extract)
                print(f"Finished parsing the data")
                property_result["legislation_extracts"].append(parsed_data)

        # print("get legislation extract: ", legislation.legislation)
        # for leg_key, leg_info in legislation.legislation.items():
        #     print("Leg key: ", leg_key, "Leg info:", leg_info)
        #     for regulations in property_to_regulations[property]:
        #         print("Legislation:", leg_info.name)
        #         article_content = extract_legislation_text(regulations, leg_info.url, leg_info.article_extract)
        #         parsed_data = parse_legislation_text(regulations, article_content)
        #         property_result["legislation_extracts"].append(parsed_data)

        results.append(property_result)

    return results


def add_llm_insights(metrics_data: list[dict], api_key: str) -> list[dict]:
    """
    Adds LLM insights to the metrics data.
    metrics_data: output of get_legislation_extracts
    api_key: Google API key for LLM
    """

    for property in metrics_data:
        property["llm_insights"] = []
        try:
            llm = init_llm(api_key)
            mesg = metric_insights(
                property_name=property,
                metrics=property["computed_metrics"],
                article_extracts=property["legislation_extracts"],
                llm=llm,
            ).content
        except Exception as e:
            mesg = "Failed to initialize LLM: {}".format(str(e))

        property["llm_insights"].append(mesg)

    # print(results)
    return metrics_data
